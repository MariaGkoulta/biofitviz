{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents\n",
    "- We don't ignore biometrics with less measurements\n",
    "- We delete redundant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read pickle file from data_cleaned \n",
    "biometrics = pd.read_pickle('../data_cleaned/filtered_biometrics.pkl')\n",
    "biometrics.drop(columns=['MeasureProvidedBy'], inplace=True)\n",
    "biometrics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_values = pd.read_pickle('../data_cleaned/biometrics_mean_per_week.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_users = mean_values.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keep only columns where we have more than 20% of values\n",
    "-> After this only 58 features are kept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns which contain NaN values for 50% of the rows\n",
    "all_users.dropna(axis=1, thresh=int(0.2*len(all_users)), inplace=True)\n",
    "all_users.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read pickle file\n",
    "imputed_df = pd.read_pickle('../data_cleaned/biometrics_m10_imputed.pkl')\n",
    "imputed_df['gender_m']=mean_values['gender_m'].values\n",
    "imputed_df['gender_f']=mean_values['gender_f'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['Age', 'BMI', 'Basal Metabolic Rate', 'Bone Mass', 'Degree Of Obesity Perc',\n",
    "                   'Extra Cellular Water Perc', 'Fat Free Mass', 'Fat mass Perc', 'Height', \n",
    "                   'Intra Cellular Water', 'Left Arm Fat Perc', 'Left Leg Fat Perc', 'Metabolic Age', \n",
    "                   'Muscle Mass', 'Muscle Mass Balance Arm', 'Muscle Mass Balance Leg', \n",
    "                   'Right Arm Fat Perc', 'Right Leg Fat Perc', 'Standard Body Weight', \n",
    "                   'Total Body Water Perc', 'Trunk Fat Perc', 'Trunk Muscle Mass', \n",
    "                   'Visceral Fat Rating', 'Weight', 'gender_m', 'gender_f']\n",
    "\n",
    "imputed_df = imputed_df[columns_to_keep]\n",
    "imputed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(imputed_df)\n",
    "pd.DataFrame(scaled_data, columns=imputed_df.columns).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA to reduce dimensionality to 2 components\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(scaled_data)\n",
    "# Step 3: Create a DataFrame for the PCA result\n",
    "pca_df = pd.DataFrame(pca_result, columns=['PCA1', 'PCA2'])\n",
    "pca_df['MeasuredOnWeek'] = all_users['MeasuredOnWeek'].values  # Aligns the indexes\n",
    "pca_df['CloudId'] = all_users['CloudId'].values  # Aligns the indexes\n",
    "pca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_cloud_ids = all_users['CloudId'].unique()[:30]\n",
    "\n",
    "# Initialize a new figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Iterate over each selected CloudId and add a trace for each\n",
    "for cloud_id in unique_cloud_ids:\n",
    "    user_data = pca_df[pca_df['CloudId'] == cloud_id]\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=user_data['PCA1'],\n",
    "        y=user_data['PCA2'],\n",
    "        mode='lines+markers',\n",
    "        line_shape='spline',\n",
    "        name=f'{cloud_id[:4]}',\n",
    "        text=all_users.apply(lambda row: '<br>'.join([f'{col}: {row[col]}' for col in ['Weight', 'Basal Metabolic Rate', 'Basal Metabolic Rate Score', 'Degree Of Obesity Perc']]), axis=1),\n",
    "        hoverinfo='text',\n",
    "        marker=dict(size=2, showscale=True),  # Adjusted marker size\n",
    "        line=dict(shape='spline')\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='2D PCA Plot of User Data by Week with Temporal Evolution',\n",
    "    xaxis_title='PCA1',\n",
    "    yaxis_title='PCA2',\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster biometrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bio = imputed_df.copy()\n",
    "bio_mean = bio.mean()\n",
    "bio_std = bio.std()\n",
    "bio['CloudId'] = all_users['CloudId'].values  # Aligns the indexes\n",
    "bio['MeasuredOnWeek'] = all_users['MeasuredOnWeek'].values  # Aligns the indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "bio_features = bio.drop(columns=['CloudId', 'MeasuredOnWeek'])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "bio_scaled = scaler.fit_transform(bio_features)\n",
    "\n",
    "num_clusters = 6  # Adjust the number of clusters as needed\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "bio['Cluster'] = kmeans.fit_predict(bio_scaled)\n",
    "\n",
    "# Add cluster labels to the DataFrame\n",
    "bio['Cluster'] = kmeans.labels_\n",
    "\n",
    "# Optional: Visualize the clusters using PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(bio_scaled)\n",
    "pca_df_bio = pd.DataFrame(pca_result, columns=['PCA1', 'PCA2'])\n",
    "pca_df_bio['Cluster'] = bio['Cluster']\n",
    "pca_df_bio['CloudId'] = bio['CloudId']\n",
    "\n",
    "\n",
    "fig = px.scatter(\n",
    "    pca_df_bio, \n",
    "    x='PCA1', \n",
    "    y='PCA2', \n",
    "    color='Cluster', \n",
    "    title='PCA of Biometric Profiles',\n",
    "    hover_data=['CloudId'],\n",
    ")\n",
    "\n",
    "fig.update_traces(marker=dict(size=1))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df_bio.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'Cluster' and calculate the mean for each group, keeping only numerical features\n",
    "numerical_features = [col for col in bio.columns if bio[col].dtype in ['int64', 'float64']]\n",
    "\n",
    "cluster_means = bio.groupby('Cluster')[numerical_features].mean()\n",
    "\n",
    "# Add the count of records in each cluster\n",
    "cluster_counts = bio['Cluster'].value_counts().sort_index()\n",
    "cluster_means['Count'] = cluster_counts\n",
    "\n",
    "# Display the average column values for each cluster along with the count\n",
    "cluster_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_means_scaled_df = (cluster_means - bio_mean) / bio_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find the quantile for a given value\n",
    "def find_quantile(value, feature_values):\n",
    "    return np.count_nonzero(feature_values < value) / feature_values.size\n",
    "\n",
    "# Find the quantile for each cluster mean\n",
    "cluster_quantiles = pd.DataFrame(index=cluster_means.index, columns=cluster_means.columns)\n",
    "\n",
    "for feature in cluster_means.columns:\n",
    "    if feature == 'Count':\n",
    "        continue\n",
    "    feature_values = bio[feature].values\n",
    "    for cluster in cluster_means.index:\n",
    "        cluster_mean = cluster_means.at[cluster, feature]\n",
    "        quantile = find_quantile(cluster_mean, feature_values)\n",
    "        cluster_quantiles.at[cluster, feature] = quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x% of the data points for that feature in the original dataset are less\n",
    "# than the cluster mean.\n",
    "cluster_quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert cluster_quantiles to numeric\n",
    "cluster_quantiles_numeric = cluster_quantiles.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(cluster_quantiles_numeric.drop(columns=['Count']), annot=True, cmap='viridis')\n",
    "plt.title('Heatmap of Quantiles for Cluster Means')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot cluster means for each feature without counts dont show counts\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(cluster_means_scaled_df.drop(columns=['Count', 'Basal Metabolic Rate']), annot=False, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Cluster Means for Biometric Features')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "bio_features = bio.drop(columns=['CloudId', 'MeasuredOnWeek'])\n",
    "\n",
    "# Standardize the Data\n",
    "scaler = StandardScaler()\n",
    "bio_scaled = scaler.fit_transform(bio_features)\n",
    "\n",
    "# Apply t-SNE for visualization\n",
    "tsne = TSNE(n_components=2, perplexity=40, max_iter=2000, random_state=42)\n",
    "tsne_result = tsne.fit_transform(bio_scaled)\n",
    "tsne_df_bio = pd.DataFrame(tsne_result, columns=['TSNE1', 'TSNE2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_df_bio['CloudId'] = bio['CloudId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "# Apply Clustering\n",
    "num_clusters = 4 # Adjust the number of clusters as needed\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "bio['Cluster'] = kmeans.fit_predict(bio_scaled)\n",
    "tsne_df_bio['Cluster'] = bio['Cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data with Seaborn and Matplotlib\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Define a color palette\n",
    "palette = sns.color_palette(\"viridis\", num_clusters)\n",
    "\n",
    "# Plot the clusters\n",
    "sns.scatterplot(\n",
    "    x='TSNE1', \n",
    "    y='TSNE2', \n",
    "    hue='Cluster', \n",
    "    palette=palette, \n",
    "    data=tsne_df_bio, \n",
    "    legend='full', \n",
    "    s=5 # Marker size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "\n",
    "# Apply UMAP for visualization\n",
    "umap_reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "umap_result = umap_reducer.fit_transform(bio_scaled)\n",
    "umap_df_bio = pd.DataFrame(umap_result, columns=['UMAP1', 'UMAP2'])\n",
    "umap_df_bio['Cluster'] = bio_sample['Cluster']\n",
    "umap_df_bio['CloudId'] = bio_sample['CloudId']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data with Seaborn and Matplotlib\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Define a color palette\n",
    "palette = sns.color_palette(\"viridis\", num_clusters)\n",
    "\n",
    "# Plot the clusters\n",
    "sns.scatterplot(\n",
    "    x='UMAP1', \n",
    "    y='UMAP2', \n",
    "    hue='Cluster', \n",
    "    palette=palette, \n",
    "    data=umap_df_bio, \n",
    "    legend='full', \n",
    "    s=3  # Marker size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge bio and pca_df on cloudid and keep only the columns with PCA1 and PCA2\n",
    "bio_pca = pd.merge(bio, pca_df, on=['CloudId', 'MeasuredOnWeek'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a subset of unique CloudId values (e.g., the first 30 unique CloudIds)\n",
    "import plotly.graph_objects as go\n",
    "unique_cloud_ids = pca_df_bio['CloudId'].unique()[:30]\n",
    "\n",
    "# Initialize a new figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Iterate over each selected CloudId and add a trace for each\n",
    "for cloud_id in unique_cloud_ids:\n",
    "    user_data = pca_df_bio[pca_df_bio['CloudId'] == cloud_id]\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=user_data['PCA1'],\n",
    "        y=user_data['PCA2'],\n",
    "        mode='lines+markers',\n",
    "        line_shape='spline',\n",
    "        text=user_data.apply(lambda row: '<br>'.join([f'{col}: {row[col]}' for col in ['Cluster']]), axis=1),\n",
    "        # text=user_data.apply(lambda row: '<br>'.join([f'{col}: {row[col]}' for col in ['Weight', 'Basal Metabolic Rate', 'Basal Metabolic Rate Score', 'Degree Of Obesity Perc', 'Cluster']]), axis=1),\n",
    "        # hoverinfo='text',\n",
    "        marker_color=user_data['Cluster'],  # Adjusted marker size and color by cluster\n",
    "        line=dict(shape='spline'),\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='2D PCA Plot of User Data by Week with Temporal Evolution',\n",
    "    xaxis_title='PCA1',\n",
    "    yaxis_title='PCA2',\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "# Add a legend to the plot\n",
    "fig.update_layout(\n",
    "    legend_title_text='Cluster',\n",
    "    legend_title_font_size=16,\n",
    "    legend_font_size=12\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by CloudId and count the number of unique clusters for each user\n",
    "user_cluster_counts = bio.groupby('CloudId')['Cluster'].nunique()\n",
    "\n",
    "# Filter users who have more than one distinct cluster\n",
    "users_with_multiple_clusters = user_cluster_counts[user_cluster_counts > 1]\n",
    "\n",
    "# Get the number of such users\n",
    "num_users_with_multiple_clusters = users_with_multiple_clusters.shape[0]\n",
    "\n",
    "total_users = bio['CloudId'].nunique()\n",
    "percentage_users_with_multiple_clusters = (num_users_with_multiple_clusters / total_users) * 100\n",
    "\n",
    "percentage_users_with_multiple_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep only those users and perform analysis only to them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bio['PCA1'] = pca_df_bio['PCA1'].values\n",
    "bio['PCA2'] = pca_df_bio['PCA2'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the bio DataFrame to keep only those users with multiple clusters\n",
    "bio_filtered = bio[bio['CloudId'].isin(users_with_multiple_clusters.index)]\n",
    "\n",
    "# Display the shape of the filtered DataFrame\n",
    "bio_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store to file\n",
    "bio_filtered.to_pickle('../data_cleaned/biometrics_m10_imputed_clustered_changes.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "umap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
